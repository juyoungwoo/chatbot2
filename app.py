import streamlit as st
import os
import tempfile
from langchain_groq import ChatGroq
from langchain_community.document_loaders import PyPDFLoader
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain.text_splitter import CharacterTextSplitter
from langchain_community.vectorstores import FAISS
from langchain.chains import RetrievalQAWithSourcesChain
from langchain.prompts.chat import (
    ChatPromptTemplate,
    SystemMessagePromptTemplate,
    HumanMessagePromptTemplate,
)
from google.oauth2 import service_account
from googleapiclient.discovery import build

# âœ… Groq API í‚¤ ì„¤ì •
os.environ["GROQ_API_KEY"] = st.secrets["GROQ_API_KEY"]

# âœ… ì„ë² ë”© ëª¨ë¸ ìºì‹± (ë©”ëª¨ë¦¬ ì ˆì•½)
@st.cache_resource
def get_embeddings():
    return HuggingFaceEmbeddings(
        model_name="sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"
    )

# âœ… Google Drive API ì´ˆê¸°í™”
@st.cache_resource
def init_drive_service():
    credentials = service_account.Credentials.from_service_account_info(
        st.secrets["google_credentials"],
        scopes=['https://www.googleapis.com/auth/drive.readonly']
    )
    return build('drive', 'v3', credentials=credentials)

# âœ… PDF íŒŒì¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
def get_pdf_files(service, folder_id):
    try:
        results = service.files().list(
            q=f"'{folder_id}' in parents and mimeType='application/pdf'",
            fields="files(id, name)"
        ).execute()
        return results.get('files', [])
    except Exception as e:
        st.error(f"Google Drive API ì˜¤ë¥˜: {str(e)}")
        return []

# âœ… Streamlit UI ì‹œì‘
st.title("ğŸ“„ IPRì‹¤ ë§¤ë‰´ì–¼ AI ì±—ë´‡")
st.write("â˜† ìë£Œ ìˆ˜ì • ë˜ëŠ” ì¶”ê°€ í¬ë§ì‹œ ì£¼ì˜ ì—°êµ¬ì› ì—°ë½ â˜†")

try:
    # âœ… Google Driveì—ì„œ PDF ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
    service = init_drive_service()
    FOLDER_ID = '1fThzSsDTeZA6Zs1VLGNPp6PejJJVydra'
    pdf_files = get_pdf_files(service, FOLDER_ID)

    if not pdf_files:
        st.warning("ğŸ“‚ ë§¤ë‰´ì–¼ í´ë”ì— PDF íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
    else:
        st.info(f"ğŸ“„ ì´ {len(pdf_files)}ê°œì˜ ë§¤ë‰´ì–¼ì„ ë¶„ì„ ì¤‘...")

        # âœ… ëª¨ë“  PDF íŒŒì¼ ì²˜ë¦¬ ë° ì„ë² ë”© ë²¡í„° ì €ì¥
        @st.cache_resource
        def process_all_pdfs():
            all_texts = []

            for pdf in pdf_files:
                try:
                    request = service.files().get_media(fileId=pdf['id'])
                    file_content = request.execute()

                    with tempfile.NamedTemporaryFile(delete=False, suffix='.pdf') as temp_file:
                        temp_file.write(file_content)
                        pdf_path = temp_file.name

                    loader = PyPDFLoader(pdf_path)
                    documents = loader.load()

                    for doc in documents:
                        doc.metadata['source'] = pdf['name']

                    all_texts.extend(documents)

                    os.unlink(pdf_path)  # ì‚¬ìš© í›„ íŒŒì¼ ì‚­ì œ

                except Exception as e:
                    st.warning(f"âš ï¸ {pdf['name']} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

            # âœ… ë¬¸ì„œ ë¶„í•  ìµœì í™”
            text_splitter = CharacterTextSplitter(
                chunk_size=500,  
                chunk_overlap=200,  
                separator="\n"  
            )
            split_texts = text_splitter.split_documents(all_texts)

            # âœ… ë²¡í„° ì €ì¥ì†Œ ìƒì„± ë° ìºì‹±
            embeddings = get_embeddings()
            vector_store = FAISS.from_documents(split_texts, embeddings)

            return vector_store

        # âœ… ë²¡í„° ìŠ¤í† ì–´ ìƒì„±
        vector_store = process_all_pdfs()
        retriever = vector_store.as_retriever(search_kwargs={"k": 3})  # ê²€ìƒ‰ ê²°ê³¼ ìµœì í™”

        # âœ… AI í”„ë¡¬í”„íŠ¸ ì„¤ì •
        system_template = """
        Use the following pieces of context to answer the user's question concisely.
        If you don't know the answer, just say "I don't know", don't try to make up an answer.
        If possible, mention the document (source) the information comes from.
        ----------------
        {summaries}
        You MUST answer in Korean and in Markdown format:
        """
        messages = [
            SystemMessagePromptTemplate.from_template(system_template),
            HumanMessagePromptTemplate.from_template("{question}")
        ]
        prompt = ChatPromptTemplate.from_messages(messages)
        chain_type_kwargs = {"prompt": prompt}

        # âœ… LLM ëª¨ë¸ ì„¤ì • ìµœì í™”
        llm = ChatGroq(
            model_name="llama-3.1-8b-instant",
            temperature=0,
            groq_api_key=os.environ["GROQ_API_KEY"],
            max_tokens=512  # ì‘ë‹µ ê¸¸ì´ ì œí•œ
        )

        # âœ… QA ì²´ì¸ ì„¤ì •
        chain = RetrievalQAWithSourcesChain.from_chain_type(
            llm=llm,
            chain_type="stuff",
            retriever=retriever,
            return_source_documents=True,
            chain_type_kwargs=chain_type_kwargs
        )

        # âœ… ì‚¬ìš©ì ì§ˆë¬¸ ì…ë ¥
        query = st.text_area("ğŸ“ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”:", height=100)  # ê¸´ ì§ˆë¬¸ ì…ë ¥ ê°€ëŠ¥
        if st.button("ğŸ’¬ ì§ˆë¬¸í•˜ê¸°") and query.strip():
            with st.spinner("ğŸ¤– ë‹µë³€ ìƒì„± ì¤‘..."):
                try:
                    result = chain({"question": query}, return_only_outputs=True)
                    answer = result.get("answer", "âŒ ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                    st.markdown(answer)
                except Exception as e:
                    st.error(f"âš ï¸ ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

except Exception as e:
    st.error(f"ğŸš¨ ì‹œìŠ¤í…œ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
